{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7dd6e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def strategy(df, config_dict):\n",
    "    \n",
    "    data_url = \"https://crypto.fin.cloud.ainode.ai/a71eaf04-802f-40be-93c2-5bee2548f4db/get/info/coin\"\n",
    "    response = requests.get(data_url)\n",
    "    data = response.json()\n",
    "\n",
    "    symbols = []\n",
    "    for item in data['data']:\n",
    "        symbols.append(item['coin_nm'] + 'USDT')\n",
    "\n",
    "    def get_bitget_history_ohlcv(symbols, days_to_fetch, granularity='1D', product_type='umcbl'):\n",
    "        \"\"\"\n",
    "        Bitget APIÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ïó¨Îü¨ Ï¢ÖÎ™©Ïùò ÏùºÎ¥â OHLCV Îç∞Ïù¥ÌÑ∞Î•º Í∞ÄÏ†∏ÏòµÎãàÎã§.\n",
    "        APIÏùò 200Í∞ú Ï†úÌïúÏùÑ Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌïú ÌéòÏù¥ÏßÄÎÑ§Ïù¥ÏÖò Î°úÏßÅÏùÑ Ìè¨Ìï®Ìï©ÎãàÎã§.\n",
    "\n",
    "        Args:\n",
    "            symbols (list): Îç∞Ïù¥ÌÑ∞Î•º Í∞ÄÏ†∏Ïò¨ Ïã¨Î≥º Î¶¨Ïä§Ìä∏ (Ïòà: ['BTCUSDT', 'ETHUSDT'])\n",
    "            days_to_fetch (int): Í∞ÄÏ†∏Ïò¨ Îç∞Ïù¥ÌÑ∞Ïùò ÎÇ†Ïßú Ïàò (Ïòà: 500)\n",
    "            granularity (str): Ï∫îÎì§ Ï£ºÍ∏∞ ('1D'Îäî ÏùºÎ¥â)\n",
    "            product_type (str): ÏÉÅÌíà ÌÉÄÏûÖ ('umcbl'ÏùÄ USDT ÏÑ†Î¨º)\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: MultiIndex Ïª¨ÎüºÏùÑ Í∞ÄÏßÑ OHLCV Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ.\n",
    "                            (Î†àÎ≤® 0: Ïã¨Î≥º, Î†àÎ≤® 1: o, h, l, c, v Îì±)\n",
    "        \"\"\"\n",
    "        base_url = \"https://api.bitget.com\"\n",
    "        endpoint = \"/api/v2/mix/market/history-candles\"\n",
    "        url = base_url + endpoint\n",
    "\n",
    "        all_symbols_data = []\n",
    "\n",
    "        for symbol in symbols:\n",
    "            \n",
    "            all_candles = []\n",
    "            # BitgetÏùÄ endTimeÏùÑ Í∏∞Ï§ÄÏúºÎ°ú Í≥ºÍ±∞ Îç∞Ïù¥ÌÑ∞Î•º Ï°∞ÌöåÌïòÎØÄÎ°ú, ÌòÑÏû¨ ÏãúÍ∞ÑÎ∂ÄÌÑ∞ ÏãúÏûë\n",
    "            end_time_ms = int(datetime.now().timestamp() * 1000)\n",
    "\n",
    "            while len(all_candles) < days_to_fetch:\n",
    "                params = {\n",
    "                    'symbol': symbol,\n",
    "                    'granularity': granularity,\n",
    "                    'productType': product_type,\n",
    "                    'limit': 200,  # API ÏµúÎåÄ ÏöîÏ≤≠ Í∞úÏàò\n",
    "                    'endTime': end_time_ms\n",
    "                }\n",
    "\n",
    "                try:\n",
    "                    response = requests.get(url, params=params)\n",
    "                    response.raise_for_status()  # HTTP ÏóêÎü¨ Î∞úÏÉù Ïãú ÏòàÏô∏ Ï≤òÎ¶¨\n",
    "                    data = response.json()\n",
    "\n",
    "                    if data.get('code') != '00000':\n",
    "                        # print(f\"[{symbol}] API Ïò§Î•ò: {data.get('msg')}\")\n",
    "                        break\n",
    "\n",
    "                    candles = data.get('data', [])\n",
    "                    if not candles:\n",
    "                        # print(f\"[{symbol}] Îçî Ïù¥ÏÉÅ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
    "                        break\n",
    "                    \n",
    "                    # Ï§ëÎ≥µ Ï†ÄÏû•ÏùÑ ÎßâÍ∏∞ ÏúÑÌï¥ Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏôÄ Í≤πÏπòÏßÄ ÏïäÎäî Î∂ÄÎ∂ÑÎßå Ï∂îÍ∞Ä\n",
    "                    new_candles = [c for c in candles if c not in all_candles]\n",
    "                    all_candles.extend(new_candles)\n",
    "\n",
    "                    # Í∞ÄÏû• Ïò§ÎûòÎêú Îç∞Ïù¥ÌÑ∞Ïùò ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑÎ•º Îã§Ïùå ÏöîÏ≤≠Ïùò endTimeÏúºÎ°ú ÏÑ§Ï†ï\n",
    "                    oldest_ts = int(candles[0][0])\n",
    "                    end_time_ms = oldest_ts - 1 # 1msÎ•º ÎπºÏÑú Ï§ëÎ≥µ Ï°∞Ìöå Î∞©ÏßÄ\n",
    "                    \n",
    "                    # API ÏÜçÎèÑ Ï†úÌïúÏùÑ ÌîºÌïòÍ∏∞ ÏúÑÌïú ÏïΩÍ∞ÑÏùò ÎåÄÍ∏∞ ÏãúÍ∞Ñ\n",
    "                    time.sleep(0.2) \n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    break\n",
    "            \n",
    "            if not all_candles:\n",
    "                continue\n",
    "            \n",
    "            # ÏàòÏßëÎêú Îç∞Ïù¥ÌÑ∞Î•º DataFrameÏúºÎ°ú Î≥ÄÌôò\n",
    "            df = pd.DataFrame(all_candles, columns=['timestamp', 'open', 'high', 'low', 'close', 'base_volume', 'volume'])\n",
    "            \n",
    "            # ÌïÑÏöîÌïú Ïª¨ÎüºÎßå ÏÑ†ÌÉùÌïòÍ≥† Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ Î≥ÄÌôò\n",
    "            df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "            df = df.astype(float)\n",
    "            \n",
    "            # ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑÎ•º ÎÇ†Ïßú/ÏãúÍ∞Ñ Ïù∏Îç±Ïä§Î°ú Î≥ÄÌôò\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            df.set_index('timestamp', inplace=True)\n",
    "            \n",
    "            # Ï†ÑÎûµÏóêÏÑú ÏöîÍµ¨ÌïòÎäî MultiIndex Ïª¨Îüº ÌòïÏãùÏúºÎ°ú Î≥ÄÍ≤Ω\n",
    "            df.columns = pd.MultiIndex.from_product([[symbol], df.columns])\n",
    "            \n",
    "            all_symbols_data.append(df)\n",
    "        \n",
    "        if not all_symbols_data:\n",
    "            return None\n",
    "\n",
    "        # Î™®Îì† Ï¢ÖÎ™©Ïùò Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏùÑ ÌïòÎÇòÎ°ú Î≥ëÌï©\n",
    "        final_df = pd.concat(all_symbols_data, axis=1)\n",
    "        \n",
    "        # Îç∞Ïù¥ÌÑ∞Î•º ÏãúÍ∞ÑÏàúÏúºÎ°ú Ï†ïÎ†¨ÌïòÍ≥† ÏöîÏ≤≠Ìïú ÎÇ†ÏßúÎßåÌÅºÎßå Î∞òÌôò\n",
    "        final_df.sort_index(inplace=True)\n",
    "        return final_df.tail(days_to_fetch)\n",
    "    \n",
    "    target_symbols = symbols\n",
    "    # target_symbols = ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT']\n",
    "\n",
    "    days = 60\n",
    "    df = get_bitget_history_ohlcv(symbols=target_symbols, days_to_fetch=days)\n",
    "\n",
    "    \"\"\"\n",
    "    Expected df format:\n",
    "    - Index: datetime\n",
    "    - Columns: pandas MultiIndex with level 0 as symbol (e.g., 'BTCUSDT') and\n",
    "               level 1 as metric (e.g., 'close', 'volume').\n",
    "    \"\"\"\n",
    "    # --- Input validation ---\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input 'df' must be a pandas DataFrame.\")\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Input DataFrame 'df' is empty.\")\n",
    "    if not isinstance(config_dict, dict):\n",
    "        raise TypeError(\"'config_dict' must be a dictionary.\")\n",
    "    \n",
    "    if not isinstance(df.columns, pd.MultiIndex):\n",
    "        raise ValueError(\"Input DataFrame 'df' must have MultiIndex columns.\")\n",
    "\n",
    "    # --- Load strategy-specific config ---\n",
    "    strategy_specific_config = config_dict.get(\"strategy_config\", {})\n",
    "    median_lookback = strategy_specific_config.get(\"median_lookback\", 60)\n",
    "    std_lookback = strategy_specific_config.get(\"std_lookback\", 60)\n",
    "    volume_z_lookback = strategy_specific_config.get(\"volume_z_lookback\", 20)\n",
    "    volume_z_threshold = strategy_specific_config.get(\"volume_z_threshold\", 1.5)\n",
    "    long_percentile = strategy_specific_config.get(\"long_percentile\", 0.01)\n",
    "    short_percentile = strategy_specific_config.get(\"short_percentile\", 0.01)\n",
    "    vol_lookback = strategy_specific_config.get(\"vol_lookback\", 30)\n",
    "    vol_target_scaler = strategy_specific_config.get(\"vol_target_scaler\", 0.0005)\n",
    "    weight_clip = strategy_specific_config.get(\"weight_clip\", 0.1)\n",
    "    dd_lookback = strategy_specific_config.get(\"dd_lookback\", 5)\n",
    "    dd_threshold = strategy_specific_config.get(\"dd_threshold\", 0.02)\n",
    "\n",
    "\n",
    "    # --- Signal Calculation ---\n",
    "    symbols = df.columns.get_level_values(0).unique()\n",
    "    final_z_scores = {}\n",
    "\n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            close_prices = df[(symbol, 'close')].ffill()\n",
    "            total_volume = df[(symbol, 'volume')].ffill()\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "\n",
    "        min_required_data = max(median_lookback, std_lookback, vol_lookback, volume_z_lookback)\n",
    "        if len(close_prices.dropna()) < min_required_data or len(total_volume.dropna()) < min_required_data:\n",
    "            continue\n",
    "\n",
    "        # 1. Price-based mean-reversion core\n",
    "        median_price = close_prices.rolling(window=median_lookback).median()\n",
    "        std_price = close_prices.rolling(window=std_lookback).std().replace(0, np.nan)\n",
    "        z_price = (close_prices - median_price) / std_price\n",
    "\n",
    "        # 2. Volume gate\n",
    "        mean_volume = total_volume.rolling(window=volume_z_lookback).mean()\n",
    "        std_volume = total_volume.rolling(window=volume_z_lookback).std().replace(0, np.nan)\n",
    "        z_volume = (total_volume - mean_volume) / std_volume\n",
    "        \n",
    "        gated_z_price = z_price.where(z_volume.abs() < volume_z_threshold, 0)\n",
    "        \n",
    "        if pd.notna(gated_z_price.iloc[-1]):\n",
    "            final_z_scores[symbol] = gated_z_price.iloc[-1]\n",
    "            \n",
    "    if not final_z_scores:\n",
    "        return {}\n",
    "        \n",
    "    # --- Cross-sectional ranking and selection ---\n",
    "    z_series = pd.Series(final_z_scores).dropna()\n",
    "    if z_series.empty:\n",
    "        return {}\n",
    "\n",
    "    ranks = z_series.rank(pct=True)\n",
    "    raw_weights = 0.5 - ranks\n",
    "\n",
    "    long_candidates = raw_weights[ranks <= long_percentile]\n",
    "    short_candidates = raw_weights[ranks >= (1.0 - short_percentile)]\n",
    "    selected_raw_weights = pd.concat([long_candidates, short_candidates])\n",
    "    \n",
    "    if selected_raw_weights.empty:\n",
    "        return {}\n",
    "\n",
    "    # --- Volatility-targeted sizing & Risk Caps ---\n",
    "    final_weights = {}\n",
    "    for symbol, raw_weight in selected_raw_weights.items():\n",
    "        close_prices = df[(symbol, 'close')].ffill()\n",
    "        daily_returns = close_prices.pct_change(1)\n",
    "        \n",
    "        vol_30 = daily_returns.rolling(window=vol_lookback).std().iloc[-1]\n",
    "        vol_30_safe = max(vol_30, 1e-6) if pd.notna(vol_30) else 1e-6\n",
    "        \n",
    "        vol_scale = vol_target_scaler / vol_30_safe\n",
    "        scaled_weight = raw_weight * vol_scale\n",
    "        \n",
    "        final_weights[symbol] = np.clip(scaled_weight, -weight_clip, weight_clip)\n",
    "\n",
    "    if not final_weights:\n",
    "        return {}\n",
    "\n",
    "    # --- Drawdown Guard (Stateless Proxy) ---\n",
    "    recent_returns = df.xs('close', axis=1, level=1).pct_change().iloc[-(dd_lookback):]\n",
    "    \n",
    "    if not recent_returns.empty:\n",
    "        simulated_pnl = pd.Series(0.0, index=recent_returns.index)\n",
    "        for symbol, weight in final_weights.items():\n",
    "            if symbol in recent_returns.columns:\n",
    "                simulated_pnl += recent_returns[symbol].fillna(0) * weight\n",
    "        \n",
    "        equity_curve = (1 + simulated_pnl).cumprod()\n",
    "        rolling_max = equity_curve.cummax()\n",
    "        drawdown = (equity_curve - rolling_max) / rolling_max\n",
    "        \n",
    "        if not drawdown.empty and drawdown.min() < -dd_threshold:\n",
    "            for symbol in final_weights:\n",
    "                final_weights[symbol] /= 2.0\n",
    "\n",
    "    # --- Final Normalization ---\n",
    "    total_abs_weight = sum(abs(w) for w in final_weights.values())\n",
    "    if total_abs_weight > 1.0:\n",
    "        for symbol, weight in final_weights.items():\n",
    "            final_weights[symbol] = weight / total_abs_weight\n",
    "            \n",
    "    return final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d197aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy_config.py\n",
    "\n",
    "strategy_config = {\n",
    "    # 1. Price-based mean-reversion core\n",
    "    \"median_lookback\": 60,       # Î°§ÎßÅ Ï§ëÍ∞ÑÍ∞í Í≥ÑÏÇ∞ Í∏∞Í∞Ñ\n",
    "    \"std_lookback\": 60,          # Î°§ÎßÅ ÌëúÏ§ÄÌé∏Ï∞® Í≥ÑÏÇ∞ Í∏∞Í∞Ñ\n",
    "\n",
    "    # 2. Volume Gate (Í±∞ÎûòÎüâ ÌïÑÌÑ∞)\n",
    "    \"volume_z_lookback\": 20,       # Ï¥ù Í±∞ÎûòÎüâ z-score Í≥ÑÏÇ∞ Í∏∞Í∞Ñ\n",
    "    \"volume_z_threshold\": 1.5,     # z-score ÌïÑÌÑ∞ÎßÅ ÏûÑÍ≥ÑÍ∞í\n",
    "\n",
    "    # 3. Cross-sectional ranking and selection (ÍµêÏ∞® ÏàúÏúÑ ÏÑ†Ï†ï)\n",
    "    \"long_percentile\": 0.01,     # Î°± Ìè¨ÏßÄÏÖò ÏßÑÏûÖÏùÑ ÏúÑÌïú ÌïòÏúÑ ÏàúÏúÑ Î∞±Î∂ÑÏú®\n",
    "    \"short_percentile\": 0.01,    # Ïàè Ìè¨ÏßÄÏÖò ÏßÑÏûÖÏùÑ ÏúÑÌïú ÏÉÅÏúÑ ÏàúÏúÑ Î∞±Î∂ÑÏú®\n",
    "\n",
    "    # 4. Volatility-targeted sizing (Î≥ÄÎèôÏÑ± Í∏∞Î∞ò ÎπÑÏ§ë Ï°∞Ï†à)\n",
    "    \"vol_lookback\": 30,          # ÏàòÏùµÎ•† Î≥ÄÎèôÏÑ± Í≥ÑÏÇ∞ Í∏∞Í∞Ñ\n",
    "    \"vol_target_scaler\": 0.0005, # Î™©Ìëú Î≥ÄÎèôÏÑ±Ïóê ÎßûÏ∂îÍ∏∞ ÏúÑÌïú Ïä§ÏºÄÏùºÎü¨\n",
    "\n",
    "    # 5. Risk caps and turnover control (Î¶¨Ïä§ÌÅ¨ Í¥ÄÎ¶¨)\n",
    "    \"weight_clip\": 0.1,        # Í∞úÎ≥Ñ ÏûêÏÇ∞Ïùò ÏµúÎåÄ ÎπÑÏ§ë (0.5%)\n",
    "\n",
    "    # 5b. Draw-down guard (ÏÜêÏã§ Ï†úÌïú)\n",
    "    \"dd_lookback\": 5,            # ÏÜêÏã§Î•† Í≥ÑÏÇ∞ Í∏∞Í∞Ñ\n",
    "    \"dd_threshold\": 0.02         # ÏÜêÏã§ Ï†úÌïú Î∞úÎèô ÏûÑÍ≥ÑÍ∞í (2%)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "302bbc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUCTIONUSDT': np.float64(0.008237956262284397),\n",
       " 'OXTUSDT': np.float64(0.007616959068619726),\n",
       " 'SNXUSDT': np.float64(-0.0031540954184424387),\n",
       " 'XAUTUSDT': np.float64(-0.03909232803415366),\n",
       " 'IMXUSDT': np.float64(-0.003868639430186473)}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = strategy(pd.DataFrame(), strategy_config)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "33bd83b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï†ïÍ∑úÌôîÎêú ÎîïÏÖîÎÑàÎ¶¨:\n",
      "{'AUCTIONUSDT': np.float64(0.13293463221623275), 'OXTUSDT': np.float64(0.12291369608610647), 'SNXUSDT': np.float64(-0.0508971522882644), 'XAUTUSDT': np.float64(-0.6308268803864082), 'IMXUSDT': np.float64(-0.062427639022988146)}\n",
      "\n",
      "Ï†ïÍ∑úÌôîÎêú Í∞íÎì§Ïùò Ï†àÎåÄÍ∞í Ìï©Í≥Ñ:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ ÎîïÏÖîÎÑàÎ¶¨\n",
    "data = weights\n",
    "\n",
    "# 1. Î™®Îì† Í∞íÏùò Ï†àÎåÄÍ∞íÏùò Ìï©Í≥Ñ Í≥ÑÏÇ∞\n",
    "total_abs_sum = sum(abs(value) for value in data.values())\n",
    "\n",
    "# 2. Í∞Å Í∞íÏùÑ Ï†àÎåÄÍ∞íÏùò Ìï©Í≥ÑÎ°ú ÎÇòÎàÑÏñ¥ Ï†ïÍ∑úÌôî\n",
    "normalized_data = {key: value / total_abs_sum for key, value in data.items()}\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"Ï†ïÍ∑úÌôîÎêú ÎîïÏÖîÎÑàÎ¶¨:\")\n",
    "print(normalized_data)\n",
    "\n",
    "# (Í≤ÄÏ¶ù) Ï†ïÍ∑úÌôîÎêú Í∞íÎì§Ïùò Ï†àÎåÄÍ∞í Ìï©Í≥ÑÍ∞Ä 1Ïù∏ÏßÄ ÌôïÏù∏\n",
    "verification_sum = sum(abs(value) for value in normalized_data.values())\n",
    "print(\"\\nÏ†ïÍ∑úÌôîÎêú Í∞íÎì§Ïùò Ï†àÎåÄÍ∞í Ìï©Í≥Ñ:\")\n",
    "print(verification_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bc110ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUCTIONUSDT': np.float64(0.008237956262284397),\n",
       " 'OXTUSDT': np.float64(0.007616959068619726),\n",
       " 'SNXUSDT': np.float64(-0.0031540954184424387),\n",
       " 'XAUTUSDT': np.float64(-0.03909232803415366),\n",
       " 'IMXUSDT': np.float64(-0.003868639430186473)}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a82ec018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUCTIONUSDT', 'OXTUSDT', 'SNXUSDT', 'XAUTUSDT', 'IMXUSDT']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68bed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "31a356d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from module.data_context import DataContext # Import the necessary module\n",
    "\n",
    "def strategy(context: DataContext, config_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Implements the Micro-structure Volatility Anomaly strategy with position limits.\n",
    "\n",
    "    This version correctly fetches historical data using the DataContext module before\n",
    "    applying the trading logic.\n",
    "    - It fetches data for a pre-defined asset list.\n",
    "    - It selects the top N long and top N short candidates based on the signal.\n",
    "    - It shorts assets with unusually high recent volatility (mean-reversion).\n",
    "    - It longs assets with unusually low recent volatility.\n",
    "    \"\"\"\n",
    "    # --- 1. Configuration Extraction ---\n",
    "    strategy_params = config_dict.get(\"strategy_config\", {})\n",
    "    assets = strategy_params.get(\"assets\", [])\n",
    "    short_vol_window = strategy_params.get(\"short_vol_window\", 20)\n",
    "    long_vol_window = strategy_params.get(\"long_vol_window\", 60)\n",
    "    clip_threshold = strategy_params.get(\"clip_threshold\", 2.0)\n",
    "    max_positions = strategy_params.get(\"max_positions\", 6)\n",
    "\n",
    "    if not assets:\n",
    "        return {} # Exit if no assets are specified\n",
    "\n",
    "    # --- 2. Data Fetching ---\n",
    "    # The total lookback period required is the sum of the two volatility windows.\n",
    "    # We add a small buffer to ensure enough data for rolling calculations.\n",
    "    total_lookback = short_vol_window + long_vol_window + 5\n",
    "    \n",
    "    hist = context.get_history(\n",
    "        assets=assets,\n",
    "        window=total_lookback,\n",
    "        frequency=\"1m\",\n",
    "        fields=[\"close\"]\n",
    "    )\n",
    "\n",
    "    # Exit if no historical data is returned\n",
    "    if hist.empty:\n",
    "        return {}\n",
    "\n",
    "    # Pivot the data to have datetime as index and assets as columns\n",
    "    df = hist[\"close\"].unstack(level=0)\n",
    "    \n",
    "    # Ensure all required assets are present after unstacking\n",
    "    tradable_assets = [asset for asset in assets if asset in df.columns]\n",
    "    if not tradable_assets:\n",
    "        return {}\n",
    "    df_filtered = df[tradable_assets]\n",
    "\n",
    "\n",
    "    # --- 3. Strategy Logic ---\n",
    "    # Step 1: Compute 1-minute percentage returns.\n",
    "    returns = df_filtered.pct_change(1)\n",
    "\n",
    "    # Step 2: Calculate short-term realized volatility.\n",
    "    vol_short = returns.rolling(window=short_vol_window, min_periods=short_vol_window).std()\n",
    "\n",
    "    # Step 3: Calculate the medium-term volatility benchmark.\n",
    "    vol_long = vol_short.rolling(window=long_vol_window, min_periods=long_vol_window).mean()\n",
    "\n",
    "    # Step 4: Form a volatility-relative signal (z-score like measure).\n",
    "    epsilon = 1e-10\n",
    "    zvol = (vol_short - vol_long) / (vol_long + epsilon)\n",
    "\n",
    "    # Step 5: Generate the final trading signal (inverted for mean-reversion).\n",
    "    signal = -zvol\n",
    "\n",
    "    # Step 6: Clip the raw signal.\n",
    "    signal_clipped = signal.clip(-clip_threshold, clip_threshold)\n",
    "\n",
    "    # --- 4. Position Selection ---\n",
    "    latest_signal = signal_clipped.iloc[-1].dropna()\n",
    "\n",
    "    if latest_signal.empty:\n",
    "        return {}\n",
    "\n",
    "    # Sort signals to find the strongest long (positive) and short (negative) candidates.\n",
    "    sorted_signals = latest_signal.sort_values(ascending=False)\n",
    "    \n",
    "    num_longs = max_positions // 2\n",
    "    num_shorts = max_positions - num_longs\n",
    "    \n",
    "    long_candidates = sorted_signals[sorted_signals > 0].head(num_longs)\n",
    "    short_candidates = sorted_signals[sorted_signals < 0].tail(num_shorts)\n",
    "    \n",
    "    final_signals = pd.concat([long_candidates, short_candidates])\n",
    "\n",
    "    if final_signals.empty:\n",
    "        return {}\n",
    "\n",
    "    # --- 5. Weight Allocation ---\n",
    "    total_abs_signal = np.abs(final_signals).sum()\n",
    "\n",
    "    if total_abs_signal > 0:\n",
    "        weights = final_signals / total_abs_signal\n",
    "    else:\n",
    "        weights = final_signals * 0\n",
    "\n",
    "    return weights.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0c851a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy_config.py\n",
    "\n",
    "strategy_config = {\n",
    "    \"assets\": [ \"OXTUSDT\", \"XRPUSDT\", \"BCHUSDT\", \"LTCUSDT\", \"AUCTIONUSDT\",\n",
    "               \"ADAUSDT\", \"ETCUSDT\", \"TRXUSDT\", \"DOTUSDT\", \"DOGEUSDT\"],\n",
    "    # Defines the lookback period (in minutes) for calculating short-term volatility.\n",
    "    # This parameter captures the most recent price fluctuation intensity.\n",
    "    \"short_vol_window\": 20,\n",
    "\n",
    "    # Defines the lookback period (in minutes) for the medium-term volatility benchmark.\n",
    "    # This acts as the baseline to which the short-term volatility is compared.\n",
    "    \"long_vol_window\": 60,\n",
    "\n",
    "    # Sets the maximum absolute value for the raw signal before normalization.\n",
    "    # This helps to mitigate the impact of extreme volatility spikes on position sizing.\n",
    "    \"clip_threshold\": 2.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "17fff0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fake 'module.data_context' module and DataContext class created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/df6gd3t56pq6t10_rqr2h7pr0000gn/T/ipykernel_3832/2785827199.py:47: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates = pd.date_range(end=datetime.now(), periods=num_periods, freq='T')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">OXTUSDT</th>\n",
       "      <th>2025-09-28 17:43:02.183134</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-28 17:44:02.183134</th>\n",
       "      <td>99.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-28 17:45:02.183134</th>\n",
       "      <td>99.900025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-28 17:46:02.183134</th>\n",
       "      <td>99.850075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-28 17:47:02.183134</th>\n",
       "      <td>99.800150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DOGEUSDT</th>\n",
       "      <th>2025-09-29 17:38:02.183134</th>\n",
       "      <td>177.515054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 17:39:02.183134</th>\n",
       "      <td>177.586060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 17:40:02.183134</th>\n",
       "      <td>177.657094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 17:41:02.183134</th>\n",
       "      <td>177.728157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 17:42:02.183134</th>\n",
       "      <td>177.799249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14400 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          close\n",
       "asset    datetime                              \n",
       "OXTUSDT  2025-09-28 17:43:02.183134  100.000000\n",
       "         2025-09-28 17:44:02.183134   99.950000\n",
       "         2025-09-28 17:45:02.183134   99.900025\n",
       "         2025-09-28 17:46:02.183134   99.850075\n",
       "         2025-09-28 17:47:02.183134   99.800150\n",
       "...                                         ...\n",
       "DOGEUSDT 2025-09-29 17:38:02.183134  177.515054\n",
       "         2025-09-29 17:39:02.183134  177.586060\n",
       "         2025-09-29 17:40:02.183134  177.657094\n",
       "         2025-09-29 17:41:02.183134  177.728157\n",
       "         2025-09-29 17:42:02.183134  177.799249\n",
       "\n",
       "[14400 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting strategy function testing...\n",
      "‚úÖ Strategy function execution complete!\n",
      "\n",
      "[Final weighted result]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUCTIONUSDT': 0.24739267395226772,\n",
       " 'LTCUSDT': 0.16221299802390304,\n",
       " 'OXTUSDT': 0.1431721793685802,\n",
       " 'DOTUSDT': -0.05556640486227585,\n",
       " 'XRPUSDT': -0.06046527983979275,\n",
       " 'BCHUSDT': -0.3311904639531804}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Fake module\n",
    "import sys\n",
    "import types\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Create a fake module called 'module' and register it with the system.\n",
    "module_obj = types.ModuleType('module')\n",
    "sys.modules['module'] = module_obj\n",
    "\n",
    "# 2. Create a fake empty module called 'module.data_context' and register it with the system.\n",
    "data_context_module = types.ModuleType('module.data_context')\n",
    "sys.modules['module.data_context'] = data_context_module\n",
    "\n",
    "# 3. Define the DataContext class required by the strategy.\n",
    "class DataContext(ABC):\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def current_dt(self) -> datetime: pass\n",
    "    @abstractmethod\n",
    "    def get_history(self, assets: list, window: int, frequency: str, fields: str or list = 'close') -> pd.DataFrame: pass\n",
    "\n",
    "# 4. Place the defined DataContext class inside the fake 'module.data_context' module.\n",
    "data_context_module.DataContext = DataContext\n",
    "\n",
    "print(\"‚úÖ Fake 'module.data_context' module and DataContext class created successfully.\")\n",
    "\n",
    "# 1. Import example strategy, config\n",
    "# from futures.anomarly_vol.anomarly_vol import strategy     # Replace with your own strategy file\n",
    "import futures.anomarly_vol.anomarly_vol_config as config  # Replace with your own config file\n",
    "\n",
    "# 2. Prepare mock objects and data required for testing.\n",
    "class MockDataContext(DataContext):\n",
    "    def __init__(self, fake_data):\n",
    "        self._fake_data = fake_data\n",
    "\n",
    "    @property\n",
    "    def current_dt(self) -> datetime:\n",
    "        return datetime.now()\n",
    "\n",
    "    def get_history(self, assets, window, frequency, fields):\n",
    "        return self._fake_data[fields]\n",
    "\n",
    "def create_fake_data(assets, num_periods):\n",
    "    dates = pd.date_range(end=datetime.now(), periods=num_periods, freq='T')\n",
    "    all_dfs = []\n",
    "    for i, asset in enumerate(assets):\n",
    "        trend = 1 + (i - len(assets) / 2) * 0.0001\n",
    "        prices = [100 * (trend ** j) for j in range(num_periods)]\n",
    "        df = pd.DataFrame({'close': prices}, index=dates)\n",
    "        df['asset'] = asset\n",
    "        all_dfs.append(df)\n",
    "    df_concat = pd.concat(all_dfs).reset_index().rename(columns={'index': 'datetime'})\n",
    "    df_final = df_concat.set_index(['asset', 'datetime'])\n",
    "    display(df_final)\n",
    "    return df_final\n",
    "\n",
    "# 3. Run verify test\n",
    "test_config = {\n",
    "    \"strategy_config\": config.strategy_config\n",
    "}\n",
    "fake_data = create_fake_data(\n",
    "    assets=test_config[\"strategy_config\"][\"assets\"], num_periods=1440)\n",
    "mock_context = MockDataContext(fake_data)\n",
    "\n",
    "print(\"\\nüöÄ Starting strategy function testing...\")\n",
    "weights = strategy(context=mock_context, config_dict=test_config)\n",
    "print(\"‚úÖ Strategy function execution complete!\")\n",
    "print(\"\\n[Final weighted result]\")\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0cd09e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">OXTUSDT</th>\n",
       "      <th>2025-09-28 17:36:13.251379</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-28 17:37:13.251379</th>\n",
       "      <td>99.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-28 17:38:13.251379</th>\n",
       "      <td>99.900025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-28 17:39:13.251379</th>\n",
       "      <td>99.850075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-28 17:40:13.251379</th>\n",
       "      <td>99.800150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DOGEUSDT</th>\n",
       "      <th>2025-09-29 17:31:13.251379</th>\n",
       "      <td>177.515054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 17:32:13.251379</th>\n",
       "      <td>177.586060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 17:33:13.251379</th>\n",
       "      <td>177.657094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 17:34:13.251379</th>\n",
       "      <td>177.728157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 17:35:13.251379</th>\n",
       "      <td>177.799249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14400 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          close\n",
       "asset    datetime                              \n",
       "OXTUSDT  2025-09-28 17:36:13.251379  100.000000\n",
       "         2025-09-28 17:37:13.251379   99.950000\n",
       "         2025-09-28 17:38:13.251379   99.900025\n",
       "         2025-09-28 17:39:13.251379   99.850075\n",
       "         2025-09-28 17:40:13.251379   99.800150\n",
       "...                                         ...\n",
       "DOGEUSDT 2025-09-29 17:31:13.251379  177.515054\n",
       "         2025-09-29 17:32:13.251379  177.586060\n",
       "         2025-09-29 17:33:13.251379  177.657094\n",
       "         2025-09-29 17:34:13.251379  177.728157\n",
       "         2025-09-29 17:35:13.251379  177.799249\n",
       "\n",
       "[14400 rows x 1 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7bc715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
